{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f603e3-0200-4840-97b6-c8b788e92ba6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scrappe Lychee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac273d9-d254-4f46-a70b-23815eae37bb",
   "metadata": {},
   "source": [
    "Website link : https://lycheethelabel.com/\n",
    "\n",
    "Goal : get all the info product + each review.\n",
    "\n",
    "+ Gets blogs information about Asian Streetwear's trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec810f6-38cf-46fe-9f5a-c8861bc7a3f4",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8e2124-3a95-4ced-801a-08401b058b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.webdriver.common.service import Service\n",
    "from selenium.webdriver.common.service import Service\n",
    "from fake_useragent import UserAgent\n",
    "from urllib3.exceptions import NewConnectionError\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import random\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208584aa-b322-4653-8f52-4d0a81180c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fonctions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2198ed-e47f-4915-bd72-29ee94d33a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    ua = UserAgent()\n",
    "    user_agent = ua.random\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1702c8fe-2da9-40d8-886f-ab05309c4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_button(driver, xpath):\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH, xpath)\n",
    "        button.click()\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Le bouton avec l'xpath '{xpath}' est introuvable.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c0322d-f763-40ee-8eae-10d8754d02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_content(driver, xpath, content_type='text', max_retries=3, timeout=8):\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            # Trouver tous les éléments correspondant à l'XPath fourni\n",
    "            elements = WebDriverWait(driver, timeout).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "            )\n",
    "\n",
    "            # Extraire le contenu spécifié pour chaque élément\n",
    "            if content_type == 'text':\n",
    "                result = [element.text for element in elements]\n",
    "            elif content_type == 'href':\n",
    "                result = [element.get_attribute('href') for element in elements]\n",
    "            else:\n",
    "                raise ValueError(\"Type de contenu non pris en charge. Utilisez 'text' ou 'href'.\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout de {timeout} secondes atteint. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Élément non trouvé. Vérifiez votre XPath. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except StaleElementReferenceException:\n",
    "            print(f\"Stale Element Reference Exception. L'élément n'est plus attaché au DOM. Réessai {retry + 1}/{max_retries}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Une erreur s'est produite : {str(e)}\")\n",
    "\n",
    "    print(f\"Impossible de trouver et extraire le contenu après {max_retries} tentatives.\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f81395-ebac-4ee0-a3e2-76b162d42ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_aleatoire(driver):\n",
    "    actions_possibles = [\"scroll_full\", \"scroll_half\", \"move_to_element\"]\n",
    "    action_choisie = random.choice(actions_possibles)\n",
    "\n",
    "    # Enregistrer la position actuelle de la page\n",
    "    current_scroll_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "\n",
    "    if action_choisie == \"scroll_full\":\n",
    "        # Action aléatoire : Faites défiler la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    elif action_choisie == \"scroll_half\":\n",
    "        # Action aléatoire : Faites défiler la moitié de la page vers le bas\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight / 2);\")\n",
    "    elif action_choisie == \"move_to_element\":\n",
    "        # Action aléatoire : Bougez la souris vers un élément aléatoire (par exemple, div de class PriceInformation_classifiedPrice__b-Jae)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        element_to_move = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'center')))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", element_to_move)\n",
    "\n",
    "    # Revenir à la position enregistrée\n",
    "    driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0512cd2-05d4-40ce-af71-2ad0a4a29dfd",
   "metadata": {},
   "source": [
    "## Scrappe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855026ae-53f5-4b44-84dd-5c07aaf2a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the driver\n",
    "driver = initialize_driver()\n",
    "\n",
    "# Load the page\n",
    "driver.get(\"https://lycheethelabel.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921927a-c3c7-42fa-9165-eeff0c8f1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plan D'action :\n",
    "\n",
    "-Blog : cliquer sur div class header-blog := aller dans le a de la div ( le href)\n",
    "\n",
    "sur chaque page recuperer tout les hrefs de blogs se trouvant dans : div class article__inner container  puis  h2  puis balise a  := recup des hrefs\n",
    "\n",
    "sur chaque page de blog .   titre = by_css_selector('h1[data-mce-fragment]')\n",
    "                            partie = by_css_selector('h2[data-mce-fragment]')\n",
    "                            paragraphe = by_css_selector('p[data-mce-fragment]')\n",
    "                            img = by_css_selector('div[data-mce-fragment]') recup limage dedans img\n",
    "                            si presence ul =  by_css_selector('ul[data-mce-fragment]') \n",
    "                        sur 14 pages ( possibiltés de threadings)\n",
    "                    \n",
    "\n",
    "les urls des pages son : vetements = https://lycheethelabel.com/collections/+ particules de parties  := exemple https://lycheethelabel.com/collections/tops pour les tops\n",
    "                         https://lycheethelabel.com/pages pour les autres particules =: exemple https://lycheethelabel.com/pages/about-us\n",
    "je vais lister les différentes possibilités et scrapper dedans. \n",
    "je vais regarder chaque nombre de page par page pour savoir combien scrapper ( facilité du  multithread)\n",
    "\n",
    "Sur page produits :   chaque balise a  class product-link ont un href := recuperer tout les hrefs et naviguer dedans\n",
    "\n",
    "dans feuille produit :\n",
    "    nom produit : h1 class title := recup text\n",
    "    prix : span class current-price theme-money := recup text\n",
    "    nombre reviews : span class jdgm-prev-badge__text := recup text\n",
    "    size = recupe le ul de class clickyboxes options--size . parcourir chaque li et recup leur text\n",
    "    wishlist := span de class swym-fave-count := recup text\n",
    "    img produit :=   dans div class thumbnails desktop-only on recupe les img class rimage__image fade-in lazyautosizes lazyloaded recuperer le srcset via get attribute\n",
    "    img_reseau = img class snpt__img  := recuperer src\n",
    "    detail = div class content tout le texte\n",
    "    recommendation = div class title = get text\n",
    "    \n",
    "    recommendations img = dans chaque div class block-inner-inner on recupe chaque  img class rimage__image fade-in lazyautosizes lazyloaded = img srcet\n",
    "    reviews := a class jdgm-rev__prod-link  :=  recup href\n",
    "    y a  acceder := \n",
    "    un review = div class product-reviews__review-card  on itere dans chaque pour obtenir\n",
    "    \n",
    "    note general = span class metrics-widget__rating := text\n",
    "    recup:= div review__timestamp := get text\n",
    "    nom profil = a class vertical-middle := text \n",
    "    date_post= div class review__timestamp\n",
    "    lien_profil =  a class vertical-middle := get attribute href\n",
    "    image = img class lazy-img review-images__picture-img := srcset \n",
    "    note := div class star-rating review__rating := get aria-label\n",
    "    titre post = strong class review__title  := get text\n",
    "    commentaire_post = div class review__body  ; on prend le p dedans := get text\n",
    "    \n",
    "    à la fin une fois page comme faites := click sur span de class pagination__page-number pagination__page-number--icon material-icons pour aller page comme suivante du meme produit\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77b685-9a0b-43c4-b4bb-c34fe26770b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ebauche scrip pour carousell reseau\n",
    "# Replace 'next_button_xpath' with the XPath of the button to move to the next image\n",
    "next_button_xpath = \"//button[@id='nextButton']\"\n",
    "\n",
    "# Replace 'carousel_xpath' with the XPath of the element containing the carousel\n",
    "carousel_xpath = \"//div[@class='your-carousel-class']\"\n",
    "\n",
    "# Function to extract image URLs from the current carousel state\n",
    "def extract_image_urls():\n",
    "    carousel_element = driver.find_element_by_xpath(carousel_xpath)\n",
    "    carousel_html = carousel_element.get_attribute('innerHTML')\n",
    "    return [url.split('\"')[1] for url in carousel_html.split('srcset=\"')[1:]]\n",
    "\n",
    "# Click the next button and extract image URLs multiple times\n",
    "num_iterations = 5  # Adjust the number of iterations as needed\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Extract and print image URLs\n",
    "    image_urls = extract_image_urls()\n",
    "    for index, image_url in enumerate(image_urls):\n",
    "        print(f\"Image {index + 1}: {image_url}\")\n",
    "\n",
    "    # Click the next button to move to the next set of images\n",
    "    next_button = driver.find_element_by_xpath(next_button_xpath)\n",
    "    ActionChains(driver).move_to_element(next_button).click().perform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
